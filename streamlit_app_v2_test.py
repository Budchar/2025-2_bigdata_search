import streamlit as st
import requests
import time 
import json 
import uuid 

# -----------------------------------------------------------------
# 1. ì„¤ì •
# -----------------------------------------------------------------

# FastAPI ë°±ì—”ë“œ ì£¼ì†Œ (main.pyê°€ ì‹¤í–‰ë˜ëŠ” ê³³) - Mock í…ŒìŠ¤íŠ¸ ì¤‘ì—ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
BACKEND_BASE_URL = "http://127.0.0.1:8000/agent"
BACKEND_QUERY_URL = f"{BACKEND_BASE_URL}/query" # ê²€ìƒ‰ ë° RAG
BACKEND_TRANSLATE_URL = f"{BACKEND_BASE_URL}/translate_summary" # ìš”ì•½/ë²ˆì—­

# Streamlit í˜ì´ì§€ ì„¤ì • - í˜ì´ì§€ ì œëª©ê³¼ ì•„ì´ì½˜ ì„¤ì •
st.set_page_config(page_title="ë…¼ë¬¸ ê²€ìƒ‰ AI ì—ì´ì „íŠ¸", page_icon="ğŸ“„", layout="wide")
st.title("ğŸ“„ Agentic RAG ê¸°ë°˜ ë…¼ë¬¸ ê²€ìƒ‰ ë° ë¶„ì„ ë„êµ¬ (Mock Test Mode)")
st.warning("âš ï¸ í˜„ì¬ Mock Test Modeì…ë‹ˆë‹¤. ì‹¤ì œ ë°±ì—”ë“œ APIë¥¼ í˜¸ì¶œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.") 

# -----------------------------------------------------------------
# 2. ë©€í‹°í„´(Multi-turn)ì„ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬
# -----------------------------------------------------------------

if "messages" not in st.session_state:
    st.session_state.messages = []
if "search_mode" not in st.session_state:
    st.session_state.search_mode = "ì§ˆì˜ì‘ë‹µ(RAG)" 
if "translated_summaries" not in st.session_state:
    st.session_state.translated_summaries = {}
    
# --- [Expander ìƒíƒœ ê´€ë¦¬ë¥¼ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ] ---
# í‚¤ë¥¼ ì œê±°í–ˆìœ¼ë¯€ë¡œ, Expanderì˜ 'ì œëª© ë¬¸ìì—´'ì„ ê¸°ì¤€ìœ¼ë¡œ ì—´ë¦¼ ìƒíƒœë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
if "expander_states" not in st.session_state:
    st.session_state.expander_states = {} # {expander_title: True/False} í˜•íƒœë¡œ ì €ì¥


# -----------------------------------------------------------------
# 3. ì‚¬ì´ë“œë°” êµ¬ì„± (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì˜µì…˜)
# -----------------------------------------------------------------

def clear_chat_history_on_mode_change():
    """ê²€ìƒ‰ ëª¨ë“œê°€ ë³€ê²½ë˜ë©´ ëŒ€í™” ë‚´ì—­ì„ ì´ˆê¸°í™”í•˜ëŠ” ì½œë°± í•¨ìˆ˜"""
    if "mode_selector" in st.session_state and st.session_state.mode_selector != st.session_state.search_mode:
        st.session_state.messages = [] 
        st.session_state.translated_summaries = {} 
        st.session_state.expander_states = {} # <-- Expander ìƒíƒœ ì´ˆê¸°í™”
        st.session_state.search_mode = st.session_state.mode_selector

st.sidebar.header("ğŸ” ê²€ìƒ‰ ëª¨ë“œ ì„¤ì •")

selected_mode = st.sidebar.radio(
    "ì›í•˜ëŠ” ê²€ìƒ‰ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”:",
    ("ì§ˆì˜ì‘ë‹µ(RAG)", "í‚¤ì›Œë“œ ê²€ìƒ‰"),
    key="mode_selector",
    on_change=clear_chat_history_on_mode_change
)
st.session_state.search_mode = selected_mode 

st.sidebar.markdown("""
**[í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë°©ì‹ ì•ˆë‚´]**
* **ì§ˆì˜ì‘ë‹µ(RAG):** ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë¶„ì„í•˜ì—¬ ê´€ë ¨ ë…¼ë¬¸ì„ ì°¾ê³ , ê·¸ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
* **í‚¤ì›Œë“œ ê²€ìƒ‰:** ì…ë ¥í•œ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ” ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤. 
""")

# -----------------------------------------------------------------
# 4. ë…¼ë¬¸ ìš”ì•½/ë²ˆì—­ ìš”ì²­ í•¸ë“¤ëŸ¬ (Mock ì ìš©)
# -----------------------------------------------------------------

# --- [ìˆ˜ì •ëœ ë¶€ë¶„: paper_idì™€ expander_titleì„ ëª¨ë‘ ë°›ìŠµë‹ˆë‹¤] ---
def request_translation(paper_id, expander_title):
    """
    ê°œë³„ ë…¼ë¬¸ì˜ IDë¥¼ ì‚¬ìš©í•˜ì—¬ ë°±ì—”ë“œì— ìš”ì•½/ë²ˆì—­ì„ ìš”ì²­í•˜ê³  ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    if not paper_id or paper_id in st.session_state.translated_summaries:
        return

    # --- [Mock Data: API í˜¸ì¶œ ëŒ€ì‹  ì •í•´ì§„ ì‘ë‹µì„ ì‚¬ìš©] ---
    st.toast("â³ Mock ë°ì´í„°ë¡œ ìš”ì•½/ë²ˆì—­ ìš”ì²­ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤...")
    time.sleep(1.0) # ì‹¤ì œ í†µì‹  ì§€ì—° íš¨ê³¼ (1ì´ˆ ëŒ€ê¸°)
    
    mock_translation_result = {
        "summary_kr": f"[{paper_id}] ë…¼ë¬¸ì˜ í•µì‹¬ í•œêµ­ì–´ ìš”ì•½ì…ë‹ˆë‹¤: ì´ Agentic RAG ì‹œìŠ¤í…œì€ LLMê³¼ ElasticSearchë¥¼ ê²°í•©í•˜ì—¬ ë¬¸ì„œ ê²€ìƒ‰ì˜ ì •í™•ë„ë¥¼ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.",
        "summary_en": f"[{paper_id}] The core English summary of the paper: This Agentic RAG system maximizes document retrieval accuracy by combining LLMs with ElasticSearch."
    }
    # -------------------------------------------------------
    
    try:
        # Mock ë°ì´í„°ë¥¼ ì‚¬ìš©
        translation_result = mock_translation_result
        
        st.session_state.translated_summaries[paper_id] = {
            "summary_kr": translation_result.get("summary_kr", "í•œêµ­ì–´ ìš”ì•½ ì—†ìŒ"),
            "summary_en": translation_result.get("summary_en", "ì˜ì–´ ìš”ì•½ ì—†ìŒ")
        }
        st.toast(f"âœ… [{paper_id}] ë…¼ë¬¸ ìš”ì•½/ë²ˆì—­ ì™„ë£Œ!")
        
        # --- [ì¶”ê°€ëœ ë¶€ë¶„: í•´ë‹¹ Expanderë¥¼ ì—´ë¦° ìƒíƒœë¡œ ì„¤ì • (Expander ì œëª© ë¬¸ìì—´ ê¸°ì¤€)] ---
        st.session_state.expander_states[expander_title] = True


    except Exception as e:
        st.error(f"âŒ ìš”ì•½/ë²ˆì—­ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    
    # ë²„íŠ¼ í´ë¦­ í›„ ì „ì²´ ì•±ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì—¬ UIë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    st.rerun()


# -----------------------------------------------------------------
# 5. ë…¼ë¬¸ ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ í•¨ìˆ˜ 
# -----------------------------------------------------------------
def display_papers(papers, message_index): 
    """ê²€ìƒ‰ëœ ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜"""
    st.subheader(f"âœ¨ ê²€ìƒ‰ ê²°ê³¼: {len(papers)}ê±´ì˜ ê´€ë ¨ ë…¼ë¬¸")
    
    if not papers:
        st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    for i, paper in enumerate(papers):
        paper_id = paper.get('id', f'temp_{i}')
        
        # --- [Expander ì œëª© ìƒì„±] ---
        expander_title = f"{i+1}. **{paper.get('title', 'ì œëª© ì—†ìŒ')}** ({paper.get('authors', 'ì €ì ë¯¸ìƒ')})"
        # Expander ìƒíƒœê°€ session_stateì— ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ False(ë‹«í˜)ë¡œ ì„¤ì •
        is_expanded = st.session_state.expander_states.get(expander_title, False) 
        
        with st.expander(
            expander_title, # <-- ì œëª© ë¬¸ìì—´ ì‚¬ìš©
            expanded=is_expanded, # <-- ì„¸ì…˜ ìƒíƒœì— ì €ì¥ëœ ê°’ìœ¼ë¡œ ì—´ë¦¼/ë‹«í˜ ìƒíƒœ ì„¤ì •
            # key=expander_key # key ì¸ìˆ˜ëŠ” ì œê±°ë˜ì—ˆìŒ.
        ):
            # --- 5-1. ê¸°ë³¸ ì´ˆë¡ í‘œì‹œ ---
            st.markdown(f"**ğŸ“š ì´ˆë¡ (ì›ë¬¸):** {paper.get('summary', 'ìš”ì•½ ì •ë³´ ì—†ìŒ')}")
            
            # --- 5-2. ìš”ì•½/ë²ˆì—­ ê²°ê³¼ í‘œì‹œ ---
            if paper_id in st.session_state.translated_summaries:
                translated = st.session_state.translated_summaries[paper_id]
                st.markdown("---")
                st.info("âœ… ìš”ì•½/ë²ˆì—­ ê²°ê³¼")
                st.markdown(f"**ğŸ‡°ğŸ‡· í•œêµ­ì–´ ìš”ì•½:** {translated['summary_kr']}")
                st.markdown(f"**ğŸ‡ºğŸ‡¸ ì˜ì–´ ì›ë¬¸ ìš”ì•½:** {translated['summary_en']}")
                
            # --- 5-3. ë²„íŠ¼ ë° ë©”íƒ€ ì •ë³´ ---
            cols = st.columns([0.2, 0.8])
            
            with cols[0]:
                is_translated = paper_id in st.session_state.translated_summaries
                
                # --- [Critical Fix]: ë²„íŠ¼ í‚¤ì˜ ê³ ìœ ì„±ì„ UUID ì „ì²´ë¡œ ë³´ì¥í•©ë‹ˆë‹¤. ---
                # paper_id, message_index, i (ë…¼ë¬¸ ì¸ë±ìŠ¤)ë¥¼ ëª¨ë‘ í¬í•¨í•˜ê³ , 
                # ì¶©ëŒ ê°€ëŠ¥ì„±ì´ ìˆëŠ” uuid.uuid4()[:8] ëŒ€ì‹  ì „ì²´ UUIDë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
                button_key = f"translate_btn_{message_index}_{paper_id}_{i}_{uuid.uuid4()}" 
                
                st.button(
                    "ğŸ¤– ìš”ì•½/ë²ˆì—­ ìš”ì²­", 
                    key=button_key, # <-- ê³ ìœ ì„± í™•ë³´
                    on_click=request_translation, 
                    args=(paper_id, expander_title), # <-- expander_titleì„ ì¸ìˆ˜ë¡œ ì¶”ê°€ ì „ë‹¬
                    disabled=is_translated, 
                    help="AI ì—ì´ì „íŠ¸ì—ê²Œ ì´ ë…¼ë¬¸ì˜ ìš”ì•½ê³¼ ë²ˆì—­ì„ ìš”ì²­í•©ë‹ˆë‹¤."
                )

            with cols[1]:
                url = paper.get('url')
                if url:
                    st.link_button("ğŸ”— ì›ë¬¸ ë°”ë¡œê°€ê¸°", url=url, help="ë…¼ë¬¸ì˜ ì›ë¬¸ í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.")

            st.caption(f"ë…¼ë¬¸ ID: {paper_id}")


# -----------------------------------------------------------------
# 6. ì±„íŒ… UI êµ¬ì„± (ë©”ì¸ í™”ë©´) (Mock ì ìš©)
# -----------------------------------------------------------------

# (A) ì €ì¥ëœ ë©”ì‹œì§€(st.session_state.messages)ë¥¼ ìˆœíšŒí•˜ë©° í™”ë©´ì— ì¶œë ¥
for msg_idx, message in enumerate(st.session_state.messages): 
    with st.chat_message(message["role"]):
        # --- [ì¶”ê°€ ìˆ˜ì •: ë”•ì…”ë„ˆë¦¬ ë©”ì‹œì§€ ì²˜ë¦¬] ---
        if isinstance(message["content"], dict):
            rag_answer = message["content"].get("rag_answer")
            related_papers = message["content"].get("related_papers")
            
            if rag_answer:
                st.markdown(rag_answer) 
            
            if related_papers:
                # ë…¼ë¬¸ ëª©ë¡ì„ ì¶œë ¥í•˜ë©° Expander ìƒíƒœê°€ ë³µì›ë©ë‹ˆë‹¤.
                display_papers(related_papers, msg_idx)
            
            if not rag_answer and not related_papers:
                 st.markdown("ì—ì´ì „íŠ¸ë¡œë¶€í„° ìœ íš¨í•œ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        else:
            # ì¼ë°˜ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ (ì‚¬ìš©ì ì…ë ¥)
            st.markdown(message["content"])

# (B) ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if prompt := st.chat_input("ë…¼ë¬¸ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”."):
    
    # 1. ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ê³¼ í™”ë©´ì— ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # 2. AI ì‘ë‹µ ì²˜ë¦¬
    # AI ì‘ë‹µì´ ìƒì„±ë˜ë©´ st.rerun()ì´ ë°œìƒí•˜ë¯€ë¡œ, ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥ì€ for ë£¨í”„ì—ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤. 
    # í•˜ì§€ë§Œ, ì…ë ¥ ì§í›„ì— ì‹œê°ì  í”¼ë“œë°±ì„ ìœ„í•´ ë¨¼ì € ì¶œë ¥í•˜ê² ìŠµë‹ˆë‹¤.
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        
        # --- [Mock Data: API í˜¸ì¶œ ëŒ€ì‹  ì •í•´ì§„ ì‘ë‹µì„ ì‚¬ìš©] ---
        st.toast(f"â³ Mock ë°ì´í„°ë¡œ {st.session_state.search_mode} ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤...")
        time.sleep(2.0) # ì‹¤ì œ í†µì‹  ì§€ì—° íš¨ê³¼ (2ì´ˆ ëŒ€ê¸°)
        
        # ê²€ìƒ‰ ëª¨ë“œì— ë”°ë¥¸ Mock ì‘ë‹µ ë°ì´í„° ì •ì˜
        if st.session_state.search_mode == "ì§ˆì˜ì‘ë‹µ(RAG)":
            mock_rag_answer = f"""
            ì•ˆë…•í•˜ì„¸ìš”! `{prompt}`ì— ëŒ€í•œ ì§ˆì˜ì‘ë‹µ ê²°ê³¼ì…ë‹ˆë‹¤.
            **Agentic RAG**ëŠ” **GPT-4**ì™€ **Elasticsearch**ë¥¼ ê²°í•©í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë…¼ë¬¸(ì•„ë˜ ëª©ë¡)ì„ ì°¾ì•„ ê·¸ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì§„ë³´ëœ ê¸°ìˆ ì…ë‹ˆë‹¤.

            íŠ¹íˆ, Custom Prompt Layerì™€ CoT(Chain-of-Thought)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì˜ í’ˆì§ˆê³¼ ì¶”ë¡  ê³¼ì •ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
            ì•„ë˜ ê´€ë ¨ ë…¼ë¬¸ ëª©ë¡ì„ ì°¸ê³ í•˜ì‹œê³ , í•„ìš”í•˜ë©´ ê°œë³„ ë…¼ë¬¸ì˜ 'ìš”ì•½/ë²ˆì—­ ìš”ì²­' ë²„íŠ¼ì„ ì‚¬ìš©í•´ë³´ì„¸ìš”.
            """
        else: # í‚¤ì›Œë“œ ê²€ìƒ‰
             mock_rag_answer = f"í‚¤ì›Œë“œ ê²€ìƒ‰ ëª¨ë“œë¡œ `{prompt}`ë¥¼ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” ê´€ë ¨ì„±ì´ ë†’ì€ ë…¼ë¬¸ ëª©ë¡ì…ë‹ˆë‹¤. RAG ë‹µë³€ì€ í‚¤ì›Œë“œ ê²€ìƒ‰ ëª¨ë“œì—ì„œëŠ” ì œê³µë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."


        ai_full_response = {
            "rag_answer": mock_rag_answer,
            "related_papers": [
                {
                    "id": "A001",
                    "title": "Agentic RAG: A New Paradigm for Grounded Generation using LLMs",
                    "authors": "Kim, Lee, Park (2024)",
                    "summary": "This paper introduces the Agentic Retrieval-Augmented Generation (RAG) framework, leveraging a multi-step planning agent to improve information retrieval accuracy and contextual understanding in large language models.",
                    "url": "https://arxiv.org/abs/2405.001"
                },
                {
                    "id": "B002",
                    "title": "Hybrid Search Strategies in Vector Databases for Scientific Literature",
                    "authors": "Choi, Jang (2023)",
                    "summary": "We explore the combination of keyword-based search (Elasticsearch) and vector-based search (Embedding) to achieve superior recall and precision in academic knowledge retrieval.",
                    "url": "https://doi.org/10.1109/IJCAI.2023.002"
                }
            ]
        }
        # -------------------------------------------------------
        
        # 3. AIì˜ ì „ì²´ ì‘ë‹µ(ë”•ì…”ë„ˆë¦¬)ì„ ì„¸ì…˜ì— ì €ì¥ (ë¨¼ì € ì €ì¥í•˜ì—¬ ì¸ë±ìŠ¤ í™•ì •)
        # ì´ ì‹œì ì— ì €ì¥ì´ ë˜ì–´ì•¼ ë‹¤ìŒ Rerun ì‹œ for ë£¨í”„ì—ì„œ ì¶œë ¥ë©ë‹ˆë‹¤.
        st.session_state.messages.append({"role": "assistant", "content": ai_full_response})
        
        # 4. LLM ë‹µë³€ì„ íƒ€ì´í•‘ íš¨ê³¼ë¡œ ì¶œë ¥ (ì´ ë¶€ë¶„ì´ ì±„íŒ… ì‘ë‹µì´ ë©ë‹ˆë‹¤)
        ai_answer_text = ai_full_response.get("rag_answer", "ë…¼ë¬¸ ê²€ìƒ‰ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        response_placeholder = st.empty()
        full_response = ""
        for chunk in ai_answer_text.split():
            full_response += chunk + " "
            time.sleep(0.02) 
            response_placeholder.markdown(full_response + "â–Œ")
        response_placeholder.markdown(full_response)
        
        # 5. ë…¼ë¬¸ ëª©ë¡ì„ í˜„ì¬ ì‘ë‹µì— ë°”ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.
        if ai_full_response.get("related_papers"):
            current_message_index = len(st.session_state.messages) - 1
            # display_papers(ai_full_response["related_papers"], current_message_index) 
            # display_papersë¥¼ ì—¬ê¸°ì„œ í˜¸ì¶œí•˜ì§€ ì•Šê³ , st.rerun() í›„ for ë£¨í”„ì—ì„œ ì¶œë ¥ë˜ë„ë¡ í•©ë‹ˆë‹¤.
            # ì´ì¤‘ ì¶œë ¥ ë°©ì§€ë¥¼ ìœ„í•´ íƒ€ì´í•‘ ì¶œë ¥ í›„ì—ëŠ” st.rerun()ì„ í˜¸ì¶œí•©ë‹ˆë‹¤.
            pass

        st.toast("âœ… Mock ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ!")
    
    # AI ì‘ë‹µì´ ì™„ì „íˆ ì„¸ì…˜ì— ì €ì¥ëœ í›„, ì „ì²´ UIë¥¼ ë‹¤ì‹œ ê·¸ë¦¬ê¸° ìœ„í•´ rerunì„ í˜¸ì¶œí•©ë‹ˆë‹¤.
    st.rerun()
        

# -----------------------------------------------------------------
# 7. Mock í…ŒìŠ¤íŠ¸ ëª¨ë“œ ë³µêµ¬ ì•ˆë‚´
# -----------------------------------------------------------------
st.sidebar.markdown("---")
st.sidebar.markdown(
    """
    **Mock í…ŒìŠ¤íŠ¸ ì™„ë£Œ ì‹œ**
    
    ë°±ì—”ë“œ íŒ€ê³¼ì˜ ì—°ë™ì„ ìœ„í•´ **Mock ì½”ë“œë¥¼ ëª¨ë‘ ì œê±°**í•˜ê³ 
    **`BACKEND_QUERY_URL`**ë¡œ ìš”ì²­í•˜ëŠ” ì½”ë“œë¥¼ ë‹¤ì‹œ í™œì„±í™”í•´ì•¼ í•©ë‹ˆë‹¤.
    """
)